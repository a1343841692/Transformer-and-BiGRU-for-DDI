Understanding drug-drug interactions (DDIs) play a vital role in the fields of drug disease treatment, drug development, preventing medical error, and controlling health care-cost. Extracting potential from biomedical corpora is a major complement to the existing DDIs. Most of the existing DDI extraction (DDIE) methods do not consider the graph and structure of drug molecular, which can improve the performance of DDIE. Considering the different advantages of Bi-directional Gated Recurrent UnitÂ (BiGRU), Transformer and attention mechanism in DDIE task, a multimodal feature fusion model by combining BiGRU and Transformer (BiGGT) is constructed for DDIE. In BiGGT, the vector embeddings of medical corpora, drug molecule topology graph and structure are conducted by Word2vec, Mol2vec and GCN, respectively, BiGRU and multi-head self-attention (MHSA) are integrated into Transformer to extract the local-global contextual DDIE features, which is important for DDIE. The extensive experiment results on the DDIExtraction 2013 shared task dataset show that the BiGGT based DDIE method outperforms the state-of-the-art DDIE approaches with precision of 78.22%. BiGGT expands the application of multimodal deep learning in the field of multimodal DDIE.
